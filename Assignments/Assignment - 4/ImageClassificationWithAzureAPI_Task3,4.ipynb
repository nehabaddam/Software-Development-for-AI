{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471ab6b2",
   "metadata": {},
   "source": [
    "# Image classification with the Azure Custom Vision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5861b72",
   "metadata": {},
   "source": [
    "## Command to install required libraries:\n",
    "## pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b602a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f83367b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with valid values\n",
    "ENDPOINT = \"https://sdai.cognitiveservices.azure.com/\"\n",
    "PredictionENDPOINT = \"https://sdai-prediction.cognitiveservices.azure.com/\"\n",
    "training_key = \"56e05f26d6d84d42a99c877e392c6170\"\n",
    "prediction_key = \"e9eb4c1a158c4bfc8da8397bb161ef2c\"\n",
    "prediction_resource_id = \"/subscriptions/5cf92398-d8a0-400a-9d32-05fcb62b046b/resourceGroups/sdai3/providers/Microsoft.CognitiveServices/accounts/sdai-Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe88cd",
   "metadata": {},
   "source": [
    "## Authenticate the client\n",
    "## Instantiate a training and prediction client with your endpoint and keys. Create ApiKeyServiceClientCredentials objects with your keys, and use them with your endpoint to create a CustomVisionTrainingClient and CustomVisionPredictionClient object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62730508",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PredictionENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b7d4f",
   "metadata": {},
   "source": [
    "## Create a new Custom Vision project\n",
    "## Add the following code to your script to create a new Custom Vision service project.\n",
    "\n",
    "## See the create_project method to specify other options when you create your project (explained in the Build a classifier web portal guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1260a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "publish_iteration_name = \"classifyModel\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project_name = uuid.uuid4()\n",
    "project = trainer.create_project(project_name)\n",
    "print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b96e5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two tags in the new project\n",
    "mango_tag = trainer.create_tag(project.id, \"Mango\")\n",
    "apple_tag = trainer.create_tag(project.id, \"Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3c551",
   "metadata": {},
   "source": [
    "## Upload and tag images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48477edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding images...\n"
     ]
    }
   ],
   "source": [
    "#__file__ : Put location where your \"images\" folder is located in your system\n",
    "\n",
    "base_image_location = os.path.join (os.path.dirname(\"C:/Users/badda/Downloads/Data1/\"), \"Images\")\n",
    "\n",
    "print(\"Adding images...\")\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for image_num in range(1, 11):\n",
    "    file_name = \"mango_{}.jpg\".format(image_num)\n",
    "    with open(os.path.join (base_image_location, \"Mango\", file_name), \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[mango_tag.id]))\n",
    "\n",
    "for image_num in range(1, 11):\n",
    "    file_name = \"apple_{}.jpg\".format(image_num)\n",
    "    with open(os.path.join (base_image_location, \"Apple\", file_name), \"rb\") as image_contents:\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[apple_tag.id]))\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=image_list))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c3c7e",
   "metadata": {},
   "source": [
    "## Train the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "945377c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Completed\n",
      "Waiting 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af518a",
   "metadata": {},
   "source": [
    "## Publish the current iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "799a0876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c61830",
   "metadata": {},
   "source": [
    "## Test the prediction endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0205125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMango: 100.00%\n",
      "\tApple: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PredictionENDPOINT, prediction_credentials)\n",
    "\n",
    "with open(os.path.join (base_image_location, \"Test/test_image.jpg\"), \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a0f8e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tApple: 100.00%\n",
      "\tMango: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PredictionENDPOINT, prediction_credentials)\n",
    "\n",
    "with open(os.path.join (base_image_location, \"Test/test.jpg\"), \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aefd12",
   "metadata": {},
   "source": [
    "#Task 4: Make a small code toolkit where you upload the image in runtime and it performs classification. \n",
    "#You have to use same ipynb file to perform the task. (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c7b4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test image directory path C:/Users/badda/Downloads/Data1/Images/Test/\n",
      "Enter jpg image filename without extention apple\n",
      "\tApple: 100.00%\n",
      "\tMango: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# below is a way to dynamically upload the image by giving image directory and image file name as input to perform classification\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PredictionENDPOINT, prediction_credentials)\n",
    "\n",
    "import os\n",
    "base_image_location1 = input(\"Enter test image directory path \") \n",
    "base_image_location1 = str(base_image_location1).replace(os.path.sep, '/') + '/'\n",
    "image = input(\"Enter jpg image filename without extention \") + '.jpg'\n",
    "\n",
    "with open(os.path.join (base_image_location1, image), \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6decd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186b1843c81340c48b3df75850bc7193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='filename', options=('apple.jpg', 'test.jpg', 'test_image.jpg'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Below is one more way to uplaod images at runtime to perform classification\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "#download anu image to the below directory \n",
    "filedir = \"C:/Users/badda/Downloads/Data1/Images/Test/\"\n",
    "\n",
    "#below function is used to select the image at runtime\n",
    "@interact\n",
    "def show_images(filename=os.listdir(filedir)):\n",
    "    display(Image(filedir+filename))\n",
    "    with open(os.path.join (filedir, filename), \"rb\") as image_contents:\n",
    "        results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ef60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edacced",
   "metadata": {},
   "source": [
    "# Task 1: Execute the code properly with given sample data and solve any issues that may arise in the code.(30%)\n",
    "# Task 2: Explain what you analyzed in the code. Make a detailed report. (10%)\n",
    "# Task 3: Use any other image dataset to run the tasks above again.(20%)\n",
    "# Task 4: Make a small code toolkit where you upload the image in runtime and it performs classification. You have to use same ipynb file to perform the task. (40%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2284d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
